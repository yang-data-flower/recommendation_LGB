def tagcount(series,tags):
    """
    统计该series中不同标签的数量，可以针对多分类
    series:只含有标签的series
    tags:为标签的列表，以实际为准，比如[0,1],[1,2,3]
    """
    result = []
    countseries = series.value_counts()
    for tag in tags:
        try:
            result.append(countseries[tag])
        except:
            result.append(0)
    return result
            


def ChiMerge3(df, num_split,tags=[1,2,3],pvalue_edge=0.1,biggest=10,smallest=3,sample=None):  
    """
    df:只包含要分箱的参数列和标签两列
    num_split:初始化时划分的区间个数,适合数据量特别大的时候。
    tags：标签列表，二分类一般为[0,1]。以实际为准。
    pvalue_edge：pvalue的置信度值
    bin：最多箱的数目
    smallest:最少箱的数目
    sample:抽样的数目，适合数据量超级大的情况。可以使用抽样的数据进行分箱。百万以下不需要
    """
    import pandas as pd
    import numpy as np
    import scipy
    variable = df.columns[0]
    flag = df.columns[1]
#进行是否抽样操作
    if sample != None:
        df = df.sample(n=sample)
#     else:
#         df   
#将原始序列初始化为num_split个区间，计算每个区间中每类别的数量，放置在一个矩阵中。方便后面计算pvalue值。    
    percent = df[variable].quantile([1.0*i/num_split for i in range(num_split+1)],interpolation= "lower").drop_duplicates(keep="last").tolist()
    percent = percent[1:]
    np_regroup = []
    for i in range(len(percent)):
        if i == 0:
            tempdata = tagcount(df[df[variable]<=percent[i]][flag],tags)
            tempdata.insert(0,percent[i])
        elif i == len(percent)-1:
            tempdata = tagcount(df[df[variable]>percent[i-1]][flag],tags)
            tempdata.insert(0,percent[i])
        else:
            tempdata = tagcount(df[(df[variable]>percent[i-1])&(df[variable]<=percent[i])][flag],tags)
            tempdata.insert(0,percent[i])
        np_regroup.append(tempdata)
    np_regroup = pd.DataFrame(np_regroup)
    np_regroup = np.array(np_regroup)


#如果两个区间某一类的值都为0，就会报错。先将这类的区间合并，当做预处理吧
    i = 0
    while (i <= np_regroup.shape[0] - 2):
        check = 0
        for j in range(len(tags)):
            if np_regroup[i,j+1] ==0 and np_regroup[i+1,j+1]==0:
                check += 1
        """
        这个for循环是为了检查是否有某一个或多个标签在两个区间内都是0，如果是的话，就进行下面的合并。
        """
        if check>0:
            np_regroup[i,1:] = np_regroup[i,1:] + np_regroup[i+1,1:]
            np_regroup[i, 0] = np_regroup[i + 1, 0]
            np_regroup = np.delete(np_regroup, i + 1, 0)
            i = i - 1
        i = i + 1
 
#对相邻两个区间进行置信度计算
    chi_table = np.array([])
    for i in np.arange(np_regroup.shape[0] - 1):
        temparray = np_regroup[i:i+2,1:]
        pvalue = scipy.stats.chi2_contingency(temparray,correction=False)[1]
        chi_table = np.append(chi_table, pvalue)
    temp = max(chi_table)
    
#把pvalue最大的两个区间进行合并。注意的是，这里并没有合并一次就重新循环计算相邻区间的pvalue，而是只更新影响到的区间。
    while (1):
        #终止条件，可以根据自己的期望定制化
        if (len(chi_table) <= (biggest - 1) and temp <= pvalue_edge):
            break
        if len(chi_table)<smallest:
            break
        
        num = np.argwhere(chi_table==temp)
        for i in range(num.shape[0]-1,-1,-1):
            chi_min_index = num[i][0]
            np_regroup[chi_min_index, 1:] = np_regroup[chi_min_index, 1:] + np_regroup[chi_min_index + 1, 1:]
            np_regroup[chi_min_index, 0] = np_regroup[chi_min_index + 1, 0]
            np_regroup = np.delete(np_regroup, chi_min_index + 1, 0)

            #最大pvalue在最后两个区间的时候，只需要更新一个，删除最后一个。大家可以画图，很容易明白
            if (chi_min_index == np_regroup.shape[0] - 1):
                temparray = np_regroup[chi_min_index-1:chi_min_index+1,1:]
                chi_table[chi_min_index - 1] = scipy.stats.chi2_contingency(temparray,correction=False)[1]
                chi_table = np.delete(chi_table, chi_min_index, axis=0)
                
            #最大pvalue是最先两个区间的时候，只需要更新一个，删除第一个。
            elif (chi_min_index == 0):
                temparray = np_regroup[chi_min_index:chi_min_index+2,1:]
                chi_table[chi_min_index] = scipy.stats.chi2_contingency(temparray,correction=False)[1]
                chi_table = np.delete(chi_table, chi_min_index+1, axis=0)
            
            #最大pvalue在中间的时候，影响和前后区间的pvalue，需要更新两个值。
            else:
                # 计算合并后当前区间与前一个区间的pvalue替换
                temparray = np_regroup[chi_min_index-1:chi_min_index+1,1:]
                chi_table[chi_min_index - 1] = scipy.stats.chi2_contingency(temparray,correction=False)[1]
                # 计算合并后当前与后一个区间的pvalue替换
                temparray = np_regroup[chi_min_index:chi_min_index+2,1:]
                chi_table[chi_min_index] = scipy.stats.chi2_contingency(temparray,correction=False)[1]
                # 删除替换前的pvalue
                chi_table = np.delete(chi_table, chi_min_index + 1, axis=0)
                
        #更新当前最大的相邻区间的pvalue
        temp = max(chi_table)
    
    print("*"*40)
    print("最终相邻区间的pvalue值为：")
    print(chi_table)
    print("*"*40)

    #把结果保存成一个数据框。
    """
    可以根据自己的需求定制化。我保留两个结果。
    1. 显示分割区间，和该区间内不同标签的数量的表
    2. 为了方便pandas对该参数处理，把apply的具体命令打印出来。方便直接对数据集处理。
        serise.apply(lambda x:XXX)中XXX的位置
    """
    #将结果整合到一个表中，即上述中的第一个
    interval = []
    interval_num = np_regroup.shape[0]
    for i in range(interval_num):
        if i == 0:
            interval.append('x<=%f'%(np_regroup[i,0]))
        elif i == interval_num-1:
            interval.append('x>%f'%(np_regroup[i-1,0]))
        else:
            interval.append('x>%f and x<=%f'%(np_regroup[i-1,0],np_regroup[i,0]))
    
    result = pd.DataFrame(np_regroup)
    result[0] = interval
    result.columns = ['interval']+tags

    #整理series的命令，即上述中的第二个
    premise = "str(0) if "
    length_interval = len(interval)
    for i in range(length_interval):
        if i == length_interval-1:
            premise = premise[:-4]
            break
        premise = premise + interval[i] + " else " + 'str(%d+1)'%i + " if "

    return result,premise
